{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25805/504401715.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../spam.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category                                            Message\n",
      "0         0  Go until jurong point, crazy.. Available only ...\n",
      "1         0                      Ok lar... Joking wif u oni...\n",
      "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         0  U dun say so early hor... U c already then say...\n",
      "4         0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['Category'] = encoder.fit_transform(df['Category'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category                                            Message  \\\n",
      "0         0  Go until jurong point, crazy.. Available only ...   \n",
      "1         0                      Ok lar... Joking wif u oni...   \n",
      "2         1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3         0  U dun say so early hor... U c already then say...   \n",
      "4         0  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                   preprocessed_text  \n",
      "0  go jurong point crazy available bugis n great ...  \n",
      "1                            ok lar joking wif u oni  \n",
      "2  free entry wkly comp win fa cup final tkts may...  \n",
      "3                u dun say early hor u c already say  \n",
      "4                nah think go usf life around though  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "df['preprocessed_text'] = df['Message'].apply(preprocess)\n",
    "\n",
    "#String column\n",
    "df['preprocessed_text'] = df['preprocessed_text'].astype(str)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['preprocessed_text'], df['Category'], test_size=0.2, random_state=0, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Convert documents into a matrix\n",
    "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train).toarray()\n",
    "x_test_tfidf = tfidf_vectorizer.transform(x_test).toarray()\n",
    "\n",
    "print(x_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "def evaluate_model(true, predicted):\n",
    "    ac_score = accuracy_score(true, predicted)\n",
    "    pr_score = precision_score(true, predicted)\n",
    "    con_matrix = confusion_matrix(true, predicted)\n",
    "    return ac_score, pr_score, con_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Model performance\n",
      "- Accuracy Score: 0.9738\n",
      "- Precision Score: 0.9821\n",
      "- Confusion Matrix:\n",
      "[[895   2]\n",
      " [ 25 110]]\n",
      "GaussianNB\n",
      "Model performance\n",
      "- Accuracy Score: 0.8605\n",
      "- Precision Score: 0.4800\n",
      "- Confusion Matrix:\n",
      "[[780 117]\n",
      " [ 27 108]]\n",
      "MultinomialNB\n",
      "Model performance\n",
      "- Accuracy Score: 0.9641\n",
      "- Precision Score: 1.0000\n",
      "- Confusion Matrix:\n",
      "[[897   0]\n",
      " [ 37  98]]\n",
      "BernoulliNB\n",
      "Model performance\n",
      "- Accuracy Score: 0.9680\n",
      "- Precision Score: 1.0000\n",
      "- Confusion Matrix:\n",
      "[[897   0]\n",
      " [ 33 102]]\n",
      "Random Forest\n",
      "Model performance\n",
      "- Accuracy Score: 0.9748\n",
      "- Precision Score: 1.0000\n",
      "- Confusion Matrix:\n",
      "[[897   0]\n",
      " [ 26 109]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irpro16/ml-projects/ham-spam/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Model performance\n",
      "- Accuracy Score: 0.9632\n",
      "- Precision Score: 0.8819\n",
      "- Confusion Matrix:\n",
      "[[882  15]\n",
      " [ 23 112]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "models =  {\n",
    "    \"SVC\": SVC(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "model_list = []\n",
    "model_precision = []\n",
    "model_accuracy = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(x_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_test_pred = model.predict(x_test_tfidf)\n",
    "    \n",
    "    # Evaluate\n",
    "    model_ac, model_pr, model_cm = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    model_precision.append(model_pr)\n",
    "    model_accuracy.append(model_ac)\n",
    "    \n",
    "    print('Model performance')\n",
    "    print('- Accuracy Score: {:.4f}'.format(model_ac))\n",
    "    print('- Precision Score: {:.4f}'.format(model_pr))\n",
    "    print('- Confusion Matrix:\\n{}'.format(model_cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.964147</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.968023</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.974806</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.963178</td>\n",
       "      <td>0.881890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name  Accuracy  Precision\n",
       "0            SVC  0.973837   0.982143\n",
       "1     GaussianNB  0.860465   0.480000\n",
       "2  MultinomialNB  0.964147   1.000000\n",
       "3    BernoulliNB  0.968023   1.000000\n",
       "4  Random Forest  0.974806   1.000000\n",
       "5       AdaBoost  0.963178   0.881890"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, model_accuracy, model_precision)), columns=['Model Name', 'Accuracy', 'Precision'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
